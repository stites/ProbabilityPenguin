---
layout: post
title: VAE interpretability\: the killer app?
---

I'm slowly moving this blog to a research repository, but here are some speculative thoughts.

VAEs seem to have this ability to navigate between high scalability and
better informed structure than conventional NNs. I have a feeling this
means that it will be on the rise as "The Next Big Thing." At least,
this just means that the NN success saga is not coming to a close as far
as stopping points. There are some effects of this:
- I predict that more research papers will address VAEs.
- I predict interpretability will be a more common metric in papers.
- I predict that VAEs and transfer learning will be a thing that is comparabile to current transfer learning
- I bet causal learning and logical programming will be on the rise (probably frog leaping the bayes train), towards the end of this VAE surge

There is a lot more to go off of. I think the most interesting thing
here will be that some VAE/classical-NN architecture will be used to
invalidate incorrect beliefs about graphical models. In other words,
we will automate the feature engineering of bayesian statistics. I
would have to read more about the automated statistician to find out
how extensive it is, but I am assuming that it is not _too_ extensive
and this "Neural-VAE non-parametric graphical architecture search"
(so... NVAENPGAS) will be practical enough to solve current academic
benchmarks at low cost.

