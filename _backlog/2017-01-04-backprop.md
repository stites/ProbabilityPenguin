I'm currently doing a thorough review of, potentially deep, neural networks as
pragmatic reinforcement learning seems to have shifted into this space. That
said, given hardware constraints, my current spec constraints require
high-performance, CPU-based (for now) computation. Lets see how this goes.

### Neural networks

The term "perptron" is a pretty common one in this field. Perceptrons came about
in the 1950s and 60s from Frank Rosenblatt, but today it's more common to use
other models of artificial neurons. Perceptrons are simple, They take several
binary inputs and produce a binary output. Each input is associated with a
weight, and if the weighted sum is past some threshold, an output is generated.

![](http://neuralnetworksanddeeplearning.com/images/tikz0.png)

These can can be composed in layers, with each layer allowing for more complex
and higher-level decision making.

![](http://neuralnetworksanddeeplearning.com/images/tikz1.png)

Note that when we talk about the layers of a neural network, the weighted sum
of a layer is simply the dot product of the weights and the inputs to the
layer. We can also move the inequality `output = step (weighted sum > threshold)`
to the other side of the formula, making `output = step (weighted sum + bias > 0)`.
Bias can now be thought of as how easy it is to make a perceptron fire.

If we want to feed an input into a node twice, we also have the option to
instead feeding input once and double the weight.

### Sigmoid Neurons

Ideally, we want a small change in weights to cause only a small change in
output but this isn't usually what happens with perceptrons in practice. To
correct this, a common neuron alternative is the sigmoid neuron. These nodes
use the logistic function to output probabilities instead of binary values:
`output = logistic (w * x + bias) = 1 / (1 + exp $ (-1) * w <.> x - b)`. Where
perceptrons use a step function for activation, sigmoids are a smoothed-out
version of this.

### Simple Neural Network Architectures

Neural network with hidden layers are sometimes confusingly named multi-layer
perceptrons even though they do not contain any perceptrons. We call neural
networks where the output of one layer is the input of the next layer a
_feedforward_ neural network. This means that there are no loops in the
network. If loops exist, we call this a _recurrent neural network_.

### MINST recap

When learning something like MINST, we ideally want to output a one-hot encoded
vector of possible output categories (this is better than the bitwise output of
4: 2^4 = 16 because we can find a discrete distribution, but a bitwise output
does exist). What we would ideally like to have is an algorithm which finds the
weights and biases so that the output from the network approximates y(x) for
all training inputs. In order to do this we have to have a cost/loss/objective
function to determine how our model is performing given some labeled training
data.

### Cost functions

Usually, we end up using MSE which looks like: `C(w, b) = 1 / (2 * n) * (sum $
map (\x -> (len (y x - a))**2) xs)`. Notice that `a` depends on `x`, `w`, and
`b`. Because 

there are some terms to keep in
mind:
- _The Hadamard product (s âŠ™ t)_: also _Schur product_, is the elementwise product.

