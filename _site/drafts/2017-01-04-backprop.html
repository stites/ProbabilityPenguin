<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en-us">
<head>
   <meta http-equiv="Content-Type" content="text/html;charset=UTF-8" />
   <title>2017-01-04-backprop</title>
   <meta name="author" content="Sam Stites" />
   <!-- <link href="http://feeds.feedburner.com/stites-io" rel="alternate" title="stites.io" type="application/atom+xml" /> -->
   <!-- <meta name="readability-verification" content="QCzSs992GxmRYRKVpPeZ6LE2tS8aYKxsSSQKV8YM"/> -->

   <!-- syntax highlighting CSS -->
   <link rel="stylesheet" href="../css/syntax.css" type="text/css" />

   <!-- Homepage CSS -->
   <link rel="stylesheet" href="../css/screen.css" type="text/css" media="screen, projection" />
   <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" type="text/css" />
   <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Inconsolata|Source+Code+Pro" />
</head>
<body>
  <div class="site">
    <div class="title">
      <a href="../">Sam Stites</a>
    </div>

  <div id="content">
      <h1>
2017-01-04-backprop
</h1>

<div class="meta">
    
    
</div>

<div class="post">
<p>I’m currently doing a thorough review of, potentially deep, neural networks as pragmatic reinforcement learning seems to have shifted into this space. That said, given hardware constraints, my current spec constraints require high-performance, CPU-based (for now) computation. Lets see how this goes.</p>
<h3 id="neural-networks">Neural networks</h3>
<p>The term “perptron” is a pretty common one in this field. Perceptrons came about in the 1950s and 60s from Frank Rosenblatt, but today it’s more common to use other models of artificial neurons. Perceptrons are simple, They take several binary inputs and produce a binary output. Each input is associated with a weight, and if the weighted sum is past some threshold, an output is generated.</p>
<p><img src="http://neuralnetworksanddeeplearning.com/images/tikz0.png" /></p>
<p>These can can be composed in layers, with each layer allowing for more complex and higher-level decision making.</p>
<p><img src="http://neuralnetworksanddeeplearning.com/images/tikz1.png" /></p>
<p>Note that when we talk about the layers of a neural network, the weighted sum of a layer is simply the dot product of the weights and the inputs to the layer. We can also move the inequality <code>output = step (weighted sum &gt; threshold)</code> to the other side of the formula, making <code>output = step (weighted sum + bias &gt; 0)</code>. Bias can now be thought of as how easy it is to make a perceptron fire.</p>
<p>If we want to feed an input into a node twice, we also have the option to instead feeding input once and double the weight.</p>
<h3 id="sigmoid-neurons">Sigmoid Neurons</h3>
<p>Ideally, we want a small change in weights to cause only a small change in output but this isn’t usually what happens with perceptrons in practice. To correct this, a common neuron alternative is the sigmoid neuron. These nodes use the logistic function to output probabilities instead of binary values: <code>output = logistic (w * x + bias) = 1 / (1 + exp $ (-1) * w &lt;.&gt; x - b)</code>. Where perceptrons use a step function for activation, sigmoids are a smoothed-out version of this.</p>
<h3 id="simple-neural-network-architectures">Simple Neural Network Architectures</h3>
<p>Neural network with hidden layers are sometimes confusingly named multi-layer perceptrons even though they do not contain any perceptrons. We call neural networks where the output of one layer is the input of the next layer a <em>feedforward</em> neural network. This means that there are no loops in the network. If loops exist, we call this a <em>recurrent neural network</em>.</p>
<h3 id="minst-recap">MINST recap</h3>
<p>When learning something like MINST, we ideally want to output a one-hot encoded vector of possible output categories (this is better than the bitwise output of 4: 2^4 = 16 because we can find a discrete distribution, but a bitwise output does exist). What we would ideally like to have is an algorithm which finds the weights and biases so that the output from the network approximates y(x) for all training inputs. In order to do this we have to have a cost/loss/objective function to determine how our model is performing given some labeled training data.</p>
<h3 id="cost-functions">Cost functions</h3>
<p>Usually, we end up using MSE which looks like: <code>C(w, b) = 1 / (2 * n) * (sum $ map (\x -&gt; (len (y x - a))**2) xs)</code>. Notice that <code>a</code> depends on <code>x</code>, <code>w</code>, and <code>b</code>. Because</p>
<p>there are some terms to keep in mind: - <em>The Hadamard product (s ⊙ t)</em>: also <em>Schur product</em>, is the elementwise product.</p>
</div>

<!--
<div id="related">
  <h2>Related Posts</h2>
  <ul class="posts">
    {% for post in site.related_posts limit:3 %}
      <li><span>{{ post.date | date_to_string }}</span> &#187; <a href="{{ post.url }}">{{ post.title }}</a></li>
    {% endfor %}
  </ul>
</div>
-->

  </div>

  <div class="footer">
    <div class="contact">
      <p>
        Sam Stites<br />
        <fnz@fgvgrf.vb cipher:rot13>
      </p>
    </div>
    <div class="contact">
      <p>
        <a href="https://github.com/stites/">github.com/stites</a><br />
        <a href="https://twitter.com/samstites/">twitter.com/samstites</a><br />
      </p>
    </div>
    <div class="contact">
      <p>
        Site proudly generated by
        <a href="http://jaspervdj.be/hakyll">Hakyll</a>
      </p>

    </div>
    <!-- <div class="rss">
      <a href="http://feeds.feedburner.com/stites-io">
        <img src="/images/rss.png" alt="Subscribe to RSS Feed" />
      </a>
    </div> -->
  </div>
</div>


<!-- segment.io  -->
<script type="text/javascript">
!(function() {
  var analytics = window.analytics = window.analytics || [];
  if (!analytics.initialize) {
    if (analytics.invoked) {
      window.console && console.error && console.error("Segment snippet included twice.");
    } else {
      analytics.invoked = !0;
      analytics.methods = ["trackSubmit", "trackClick", "trackLink", "trackForm", "pageview", "identify", "reset", "group", "track", "ready", "alias", "debug", "page", "once", "off", "on"];
      analytics.factory = function(t) {
        return function() {
          var e = Array.prototype.slice.call(arguments);
          e.unshift(t);
          analytics.push(e);
          return analytics
        }
      };
      for (var t = 0; t < analytics.methods.length; t++) {
        var e = analytics.methods[t];
        analytics[e] = analytics.factory(e)
      }
      analytics.load = function(t) {
        var e = document.createElement("script");
        e.type = "text/javascript";
        e.async = !0;
        e.src = ("https:" === document.location.protocol ? "https://" : "http://") + "cdn.segment.com/analytics.js/v1/" + t + "/analytics.min.js";
        var n = document.getElementsByTagName("script")[0];
        n.parentNode.insertBefore(e, n)
      };
      analytics.SNIPPET_VERSION = "4.0.0";
      analytics.load("HVtnN0ssVfZ3s1y21RbTCebaX6IgC1qK");
      analytics.page();
    }
  }
})();
</script>
<!-- segment.io end -->

<!-- mathjax! -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.js"></script>

<!-- Disqus begin -->
<script type="text/javascript">
// /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
// var disqus_shortname = 'stites'; // required: replace example with your forum shortname

// /* * * DON'T EDIT BELOW THIS LINE * * */
// (function () {
//     var s = document.createElement('script'); s.async = true;
//     s.type = 'text/javascript';
//     s.src = '//' + disqus_shortname + '.disqus.com/count.js';
//     (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
// }());
</script>
<!-- Disqus end -->
</body>
</html>
