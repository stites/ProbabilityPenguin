<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en-us">
<head>
   <meta http-equiv="Content-Type" content="text/html;charset=UTF-8" />
   <title>Clipping, that extra bump for loss criteria</title>
   <meta name="author" content="Sam Stites" />
   <!-- <link href="http://feeds.feedburner.com/stites-io" rel="alternate" title="stites.io" type="application/atom+xml" /> -->
   <!-- <meta name="readability-verification" content="QCzSs992GxmRYRKVpPeZ6LE2tS8aYKxsSSQKV8YM"/> -->

   <!-- syntax highlighting CSS -->
   <link rel="stylesheet" href="../css/syntax.css" type="text/css" />

   <!-- Homepage CSS -->
   <link rel="stylesheet" href="../css/screen.css" type="text/css" media="screen, projection" />
   <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" type="text/css" />
   <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Inconsolata|Source+Code+Pro" />
</head>
<body>
  <div class="site">
    <div class="title">
      <a href="../">Sam Stites</a>
    </div>

  <div id="content">
      <h1>
Clipping, that extra bump for loss criteria
</h1>

<div class="meta">
    January 22, 2018
    
</div>

<div class="post">
<p>For the past couple of days I’ve been writing a transfer-learning workflow for the dog breed identification kaggle competition. This was done solely in pytorch and torchvision, heavily referencing the beginner pytorch tutorials, and you can find them at <a href="https://github.com/stites/circus/blob/master/notebooks/dog-breeds.ipynb">stites/circus</a>. This code, which doesn’t do anything fancier than a fastai notebook, was able to produce results that placed in the 50th-percentile of the competition. This isn’t enough to qualify for anything like a bronze medal on kaggle (there are ~1k participants), but as a tool to familiarize myself with a CV pipeline from scratch, I would say this is a success.</p>
<p>There are four reasons why this workflow was successful and there are a plethora of improvements to be made. First, reasons how this was successful:</p>
<ul>
<li><p>Transfer learning from Resnet152 was used. Resnet34 alone got the model up to the 75th percentile, Resnet152 trained much faster and finished training (ie, the validation-training loss balance fell out-of-whack) at the 50th epoch. The final architecture consisted of Resnet152, followed by a fully-connected layer (fc layer) of 4096, relu, another fc layer of 120, and finally softmax. Sigmoid was attempted as well, however since the results are looking for a single breed, it is not as performant.</p></li>
<li><p>Data Augmentation was used. This is a given and seems essential to any computer vision pipeline.</p></li>
<li><p>A hacked-together version of Stochastic Gradient Descent with Restarts was used. This basically was just me reinitializing the learning rate scheduler at a regular interval.</p></li>
<li><p>Clipping was used on the final result. Since there were 120 classes, the bounds were \(0.01 / 120\) and \(0.99 / 120 \). This dropped the softmax-based solution from the 60th to the 50th percentile.</p></li>
</ul>
<p>That said, there are a number of places where this could be improved:</p>
<ul>
<li><p>Test-time augmentation could be used.</p></li>
<li><p>I unfroze resnet152 so that it would have a better fit to dogs and not other imagenet images. While this is good theoretically, I think using differential learning rates would have allowed for a better speedup.</p></li>
<li><p>On the note of other fastai improvements – I’m less impressed with the learning rate finder, but it could have been a valuable asset to include.</p></li>
<li><p>I should really work with an ensemble if I want to get better results. Doing a k-folds would be an excellent way to do this. Having each GPU work with its own model would also be adequate.</p></li>
<li><p>I could do that thing where I save the fc-layer, train the full model on all of the validation set, then load the old fc-layer so that I am not overfitting on prediction, but am still able to use validation images to learn better features.</p></li>
<li><p>Using a better architecture would be nice. In particular, I was interested in using Squeeze-and-Excite networks (this year’s ImageNet winner).</p></li>
<li><p>Using Cosine Annealing for the learning rate scheduler would have been nice and would move me from using a hack of SGDR, to real SGDR.</p></li>
<li><p>A lot more data augmentation.</p></li>
<li><p>Actually using Multi Class Log Loss instead of Cross Entropy Loss. This was done out of laziness.</p></li>
<li><p>Using log softmax would make friendlier and faster gradients.</p></li>
</ul>
<p>I think the most impressive thing was that, as alluded to in the title, clipping the loss function brought down the kaggle loss from ~1.0 to the current loss (0.5843).</p>
</div>

<!--
<div id="related">
  <h2>Related Posts</h2>
  <ul class="posts">
    {% for post in site.related_posts limit:3 %}
      <li><span>{{ post.date | date_to_string }}</span> &#187; <a href="{{ post.url }}">{{ post.title }}</a></li>
    {% endfor %}
  </ul>
</div>
-->

  </div>

  <div class="footer">
    <div class="contact">
      <p>
        Sam Stites<br />
        <fnz@fgvgrf.vb cipher:rot13>
      </p>
    </div>
    <div class="contact">
      <p>
        <a href="https://github.com/stites/">github.com/stites</a><br />
        <a href="https://twitter.com/samstites/">twitter.com/samstites</a><br />
      </p>
    </div>
    <div class="contact">
      <p>
        Site proudly generated by
        <a href="http://jaspervdj.be/hakyll">Hakyll</a>
      </p>

    </div>
    <!-- <div class="rss">
      <a href="http://feeds.feedburner.com/stites-io">
        <img src="/images/rss.png" alt="Subscribe to RSS Feed" />
      </a>
    </div> -->
  </div>
</div>


<!-- segment.io  -->
<script type="text/javascript">
!(function() {
  var analytics = window.analytics = window.analytics || [];
  if (!analytics.initialize) {
    if (analytics.invoked) {
      window.console && console.error && console.error("Segment snippet included twice.");
    } else {
      analytics.invoked = !0;
      analytics.methods = ["trackSubmit", "trackClick", "trackLink", "trackForm", "pageview", "identify", "reset", "group", "track", "ready", "alias", "debug", "page", "once", "off", "on"];
      analytics.factory = function(t) {
        return function() {
          var e = Array.prototype.slice.call(arguments);
          e.unshift(t);
          analytics.push(e);
          return analytics
        }
      };
      for (var t = 0; t < analytics.methods.length; t++) {
        var e = analytics.methods[t];
        analytics[e] = analytics.factory(e)
      }
      analytics.load = function(t) {
        var e = document.createElement("script");
        e.type = "text/javascript";
        e.async = !0;
        e.src = ("https:" === document.location.protocol ? "https://" : "http://") + "cdn.segment.com/analytics.js/v1/" + t + "/analytics.min.js";
        var n = document.getElementsByTagName("script")[0];
        n.parentNode.insertBefore(e, n)
      };
      analytics.SNIPPET_VERSION = "4.0.0";
      analytics.load("HVtnN0ssVfZ3s1y21RbTCebaX6IgC1qK");
      analytics.page();
    }
  }
})();
</script>
<!-- segment.io end -->

<!-- mathjax! -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.js"></script>

<!-- Disqus begin -->
<script type="text/javascript">
// /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
// var disqus_shortname = 'stites'; // required: replace example with your forum shortname

// /* * * DON'T EDIT BELOW THIS LINE * * */
// (function () {
//     var s = document.createElement('script'); s.async = true;
//     s.type = 'text/javascript';
//     s.src = '//' + disqus_shortname + '.disqus.com/count.js';
//     (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
// }());
</script>
<!-- Disqus end -->
</body>
</html>
