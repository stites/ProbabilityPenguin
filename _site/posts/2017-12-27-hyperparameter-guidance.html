<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en-us">
<head>
   <meta http-equiv="Content-Type" content="text/html;charset=UTF-8" />
   <title>Hyperparameter guidance for ANNs</title>
   <meta name="author" content="Sam Stites" />
   <!-- <link href="http://feeds.feedburner.com/stites-io" rel="alternate" title="stites.io" type="application/atom+xml" /> -->
   <!-- <meta name="readability-verification" content="QCzSs992GxmRYRKVpPeZ6LE2tS8aYKxsSSQKV8YM"/> -->

   <!-- syntax highlighting CSS -->
   <link rel="stylesheet" href="../css/syntax.css" type="text/css" />

   <!-- Homepage CSS -->
   <link rel="stylesheet" href="../css/screen.css" type="text/css" media="screen, projection" />
   <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" type="text/css" />
   <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Inconsolata|Source+Code+Pro" />
</head>
<body>
  <div class="site">
    <div class="title">
      <a href="../">Sam Stites</a>
    </div>

  <div id="content">
      <h1>
Hyperparameter guidance for ANNs
</h1>

<div class="meta">
    December 27, 2017
    
</div>

<div class="post">
<p>When writing your next neural network you’ll need to go about selecting certain hyperparameters like number of layers, the size of each layer, how many convolutional layers, and how large your filter sizes should be.</p>
<p>Theoretically, a single neural network with a single hidden layer is a universal approximator to any function (<a href="http://www.dartmouth.edu/~gvc/Cybenko_MCSS.pdf">theory1</a>, <a href="http://neuralnetworksanddeeplearning.com/chap4.html">alternate explanation</a>). Intuitively, as well, we would assume that the less complicated the model, the less likely we will overfit our training data. However, keep in mind that when we increase the size and number of layers, the capacity to fit larger and more complex functions increases.</p>
<p>It turns out that simpler models are not flexible enough to use in practice – in part because neural networks are not convex functions. While smaller neural networks contain fewer local minima / maxima, it’s easier to fit to one of them. In contrast, in larger neural networks you have thousands to hundreds of thousands of parameters and, while there are more local maxima possible, it is less likely to settle on a local maxima which will satisfy all parameters.</p>
<p>To combat overfitting methods like regularization, dropout, and input noise are used. So the rule of thumb here is that you should preference as many layers and neurons as compute time will allow.</p>
<p>Empirically, from the Stanford cs231n notes, a fully-connected 3-layer neural networks outperforms 2-layer networks and anything deeper than that is usually is not an effective use of computation. This is the opposite for convolutional networks, where depth is found to be a very important part of representational learning. This is because, in things like computer vision and, more recently, natural language processing, hierarchical representations. For instance, a face is made of eyes, a nose, and a mouth, which are all composed of edges, angles, and curves. In NLP, a document of text may be composed of paragraphs, which are composed of sentences, which are composed of shingles of characters or words.</p>
<p>Convolutional filters are another point of interest. Empirically, it turns out that you should always use 3x3 filters according to <a href="missing">(missing citation, but found via fastai)</a>.</p>
<p>For more on this subject, <a href="https://cs231n.github.io/neural-networks-1/">Stanford’s cs231 class</a> points us in the direction of:</p>
<ul>
<li><a href="http://www.deeplearningbook.org/contents/mlp.html">Deep Learning book in press by Bengio, Goodfellow, Courville, in particular Chapter 6.4.</a></li>
<li><a href="http://arxiv.org/abs/1312.6184">Do Deep Nets Really Need to be Deep?</a></li>
<li><a href="http://arxiv.org/abs/1412.6550">FitNets: Hints for Thin Deep Nets</a></li>
</ul>
</div>

<!--
<div id="related">
  <h2>Related Posts</h2>
  <ul class="posts">
    {% for post in site.related_posts limit:3 %}
      <li><span>{{ post.date | date_to_string }}</span> &#187; <a href="{{ post.url }}">{{ post.title }}</a></li>
    {% endfor %}
  </ul>
</div>
-->

  </div>

  <div class="footer">
    <div class="contact">
      <p>
        Sam Stites<br />
        <fnz@fgvgrf.vb cipher:rot13>
      </p>
    </div>
    <div class="contact">
      <p>
        <a href="https://github.com/stites/">github.com/stites</a><br />
        <a href="https://twitter.com/samstites/">twitter.com/samstites</a><br />
      </p>
    </div>
    <div class="contact">
      <p>
        Site proudly generated by
        <a href="http://jaspervdj.be/hakyll">Hakyll</a>
      </p>

    </div>
    <!-- <div class="rss">
      <a href="http://feeds.feedburner.com/stites-io">
        <img src="/images/rss.png" alt="Subscribe to RSS Feed" />
      </a>
    </div> -->
  </div>
</div>


<!-- segment.io  -->
<script type="text/javascript">
!(function() {
  var analytics = window.analytics = window.analytics || [];
  if (!analytics.initialize) {
    if (analytics.invoked) {
      window.console && console.error && console.error("Segment snippet included twice.");
    } else {
      analytics.invoked = !0;
      analytics.methods = ["trackSubmit", "trackClick", "trackLink", "trackForm", "pageview", "identify", "reset", "group", "track", "ready", "alias", "debug", "page", "once", "off", "on"];
      analytics.factory = function(t) {
        return function() {
          var e = Array.prototype.slice.call(arguments);
          e.unshift(t);
          analytics.push(e);
          return analytics
        }
      };
      for (var t = 0; t < analytics.methods.length; t++) {
        var e = analytics.methods[t];
        analytics[e] = analytics.factory(e)
      }
      analytics.load = function(t) {
        var e = document.createElement("script");
        e.type = "text/javascript";
        e.async = !0;
        e.src = ("https:" === document.location.protocol ? "https://" : "http://") + "cdn.segment.com/analytics.js/v1/" + t + "/analytics.min.js";
        var n = document.getElementsByTagName("script")[0];
        n.parentNode.insertBefore(e, n)
      };
      analytics.SNIPPET_VERSION = "4.0.0";
      analytics.load("HVtnN0ssVfZ3s1y21RbTCebaX6IgC1qK");
      analytics.page();
    }
  }
})();
</script>
<!-- segment.io end -->

<!-- mathjax! -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.js"></script>

<!-- Disqus begin -->
<script type="text/javascript">
// /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
// var disqus_shortname = 'stites'; // required: replace example with your forum shortname

// /* * * DON'T EDIT BELOW THIS LINE * * */
// (function () {
//     var s = document.createElement('script'); s.async = true;
//     s.type = 'text/javascript';
//     s.src = '//' + disqus_shortname + '.disqus.com/count.js';
//     (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
// }());
</script>
<!-- Disqus end -->
</body>
</html>
